# 实验四：深度学习模型实现与理解笔记

本实验主要包括两个部分：基于 AlexNet 的图像分类模型训练与基于 Transformer 的 Vision Transformer 模型实现。通过对两份代码的学习与分析，掌握深度学习中两类经典模型的结构与训练流程。

---

## 一、代码 1：`train_alex.py` —— AlexNet 图像分类训练

### 1.1 功能简介
该代码实现了一个简化版 AlexNet 模型的训练流程，针对自定义图像数据集进行分类任务，涵盖数据加载、模型定义、训练与评估等完整步骤。

### 1.2 核心内容解析

#### （1）数据加载
- 使用自定义 `ImageTxtDataset` 类从 `train.txt` 读取图像路径与标签。
- 图像目录示例：`D:\dataset\image2\train`。
- 数据增强与预处理：
  - 调整图像尺寸至 224x224；
  - 应用随机水平翻转；
  - 图像转为张量；
  - 使用 ImageNet 标准均值和标准差进行归一化。

#### （2）模型构建
- 架构为简化版 **AlexNet**：
  - 包含5个卷积层和3个全连接层；
  - 使用 `ReLU` 激活与 `MaxPool2d` 池化；
  - 输出类别数为10，适配10分类任务；
  - 输入图像为RGB三通道。

#### （3）训练流程
- 批大小设为64，采用 `DataLoader` 进行加载；
- 使用 `CrossEntropyLoss` 作为损失函数；
- 采用 `SGD` 优化器（学习率0.01，动量0.9）；
- 每500步记录一次训练损失，并写入 TensorBoard；
- 每个 epoch 后进行测试评估，记录损失与准确率；
- 每轮训练完成后保存模型权重至 `.pth` 文件。

#### （4）测试流程
- 使用 `torch.no_grad()` 禁用梯度计算；
- 计算全测试集的平均损失与准确率；
- 评估结果也通过 TensorBoard 记录。

### 1.3 学习重点
- 熟悉 **自定义数据集加载与格式管理**；
- 掌握 **AlexNet 模型结构** 和修改方法；
- 掌握完整的训练测试流程（模型保存、TensorBoard使用）；
- 理解数据增强对模型泛化性能的提升作用。

---

## 二、代码 2：`transformer.py` —— Vision Transformer (ViT) 实现

### 2.1 功能简介
该代码实现了基于 Transformer 架构的 Vision Transformer（ViT）模型，适用于将图像转化为序列进行处理的任务。

### 2.2 模块详解

#### （1）网络模块构成

- **FeedForward 模块**：
  - 两层线性层 + GELU 激活 + Dropout；
  - 搭配 `LayerNorm` 进行归一化。
  
- **Attention 模块**：
  - 多头自注意力机制；
  - 使用 Softmax 计算权重；
  - 借助 `einops.rearrange` 和 `repeat` 操作调整张量形状；
  
- **Transformer 模块**：
  - 多层堆叠，每层包含注意力层和前馈层；
  - 引入残差连接；
  
- **ViT 模型主体**：
  - 将图像转为 patch 序列；
  - 添加位置嵌入和类别 token；
  - 使用 Transformer 编码整个序列；
  - 最终通过线性层输出分类结果。

#### （2）模型输入输出格式
- 输入格式：形如 `(B, C, seq_len)` 的时序图像张量；
- 输出格式：`(B, num_classes)` 的分类预测值。

#### （3）测试验证代码
- 模拟随机输入构建模型实例；
- 确认输出维度匹配，保证模型结构正确无误。

### 2.3 学习重点
- 理解 **Transformer 架构** 各组成模块（注意力、多层感知器、残差）；
- 掌握 **Vision Transformer** 的输入转化方法（patch embedding、cls token、位置编码）；
- 熟悉 `einops` 库在张量变换中的高效用法；
- 理解 ViT 在图像分类中的应用流程。

---

## 三、实验总结

本实验涵盖了两种典型的深度学习模型：

| 模型类型 | 文件名 | 学习重点 |
|----------|--------|----------|
| 卷积神经网络 (CNN) | `train_alex.py` | 模型构建、训练流程、数据增强 |
| Transformer 模型 | `transformer.py` | ViT结构、张量变换、序列建模 |

通过本实验，深入掌握了自定义数据集的使用、深度学习模型的训练与测试技巧，以及从 CNN 到 Transformer 的模型架构差异。